{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM39OVkxiwr7aqOJ5LE4jQy",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shiling2007/Python-/blob/main/20_newsgroup_word_embedding_layers_deep_learning_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "g7sSfY_7o-pn",
        "outputId": "8049c2a9-0350-4b6b-fcb3-62e6768807ef"
      },
      "source": [
        "# https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
        "\n",
        "from IPython.core.display import display, HTML, Image\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
        "# from IPython.core.interactiveshell import InteractiveShell\n",
        "# InteractiveShell.ast_node_interactivity = \"all\"\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# from google.colab import files\n",
        "# files.download('/content/drive/MyDrive/Colab Notebooks/Lease Payment Formula.ipynb') \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "np.set_printoptions(edgeitems=30, linewidth=100000, \n",
        "    formatter=dict(float=lambda x: \"%.5g\" % x))\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 10)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 999)\n",
        "pd.set_option(\"max_colwidth\", 500)\n",
        "# try:\n",
        "#  device_name = os.environ['COLAB_TPU_ADDR']\n",
        "#  TPU_ADDRESS = 'grpc://' + device_name\n",
        "#  print('Found TPU at: {}'.format(TPU_ADDRESS))\n",
        "# except KeyError:\n",
        "#  print('TPU not found')\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9IfrSfykwqu",
        "outputId": "3f105e4b-33e1-43dd-be3e-c285014805fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-18 23:07:17--  http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\n",
            "Resolving www.cs.cmu.edu (www.cs.cmu.edu)... 128.2.42.95\n",
            "Connecting to www.cs.cmu.edu (www.cs.cmu.edu)|128.2.42.95|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17329808 (17M) [application/x-gzip]\n",
            "Saving to: ‘news20.tar.gz’\n",
            "\n",
            "news20.tar.gz       100%[===================>]  16.53M  90.9KB/s    in 78s     \n",
            "\n",
            "2022-10-18 23:09:03 (216 KB/s) - ‘news20.tar.gz’ saved [17329808/17329808]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RClA_2IFk-i2",
        "outputId": "c0cc6ce3-ef07-484d-e6b6-5e3f585fbdd8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 16928\n",
            "drwxr-xr-x 1 root root     4096 Oct 17 13:44 sample_data\n",
            "-rw-r--r-- 1 root root 17329808 Jan 30  2000 news20.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzvf news20.tar.gz"
      ],
      "metadata": {
        "id": "-tHaTBTRlPce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lt 20_newsgroup"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_MagdZZnGpD",
        "outputId": "e3c7c26d-bef7-4a81-fce6-2d6fb795b1c0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 532\n",
            "drwxr-xr-x 2 6690 uucp 28672 Apr 20  1998 talk.religion.misc\n",
            "drwxr-xr-x 2 6690 uucp 24576 Apr 20  1998 talk.politics.misc\n",
            "drwxr-xr-x 2 6690 uucp 28672 Apr 20  1998 talk.politics.mideast\n",
            "drwxr-xr-x 2 6690 uucp 24576 Apr 20  1998 talk.politics.guns\n",
            "drwxr-xr-x 2 6690 uucp 24576 Apr 20  1998 soc.religion.christian\n",
            "drwxr-xr-x 2 6690 uucp 28672 Apr 20  1998 sci.space\n",
            "drwxr-xr-x 2 6690 uucp 28672 Apr 20  1998 sci.med\n",
            "drwxr-xr-x 2 6690 uucp 28672 Apr 20  1998 sci.electronics\n",
            "drwxr-xr-x 2 6690 uucp 28672 Apr 20  1998 sci.crypt\n",
            "drwxr-xr-x 2 6690 uucp 28672 Apr 20  1998 rec.sport.hockey\n",
            "drwxr-xr-x 2 6690 uucp 24576 Apr 20  1998 rec.sport.baseball\n",
            "drwxr-xr-x 2 6690 uucp 28672 Apr 20  1998 rec.motorcycles\n",
            "drwxr-xr-x 2 6690 uucp 28672 Apr 20  1998 rec.autos\n",
            "drwxr-xr-x 2 6690 uucp 28672 Apr 20  1998 misc.forsale\n",
            "drwxr-xr-x 2 6690 uucp 24576 Apr 20  1998 comp.windows.x\n",
            "drwxr-xr-x 2 6690 uucp 28672 Apr 20  1998 comp.sys.mac.hardware\n",
            "drwxr-xr-x 2 6690 uucp 28672 Apr 20  1998 comp.sys.ibm.pc.hardware\n",
            "drwxr-xr-x 2 6690 uucp 20480 Apr 20  1998 comp.os.ms-windows.misc\n",
            "drwxr-xr-x 2 6690 uucp 28672 Apr 20  1998 comp.graphics\n",
            "drwxr-xr-x 2 6690 uucp 28672 Apr 20  1998 alt.atheism\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys"
      ],
      "metadata": {
        "id": "HlRpszcUnd3u"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT_DATA_DIR='20_newsgroup'\n",
        "texts = []  # list of text samples\n",
        "labels_index = {}  # dictionary mapping label name to numeric id\n",
        "labels = []  # list of label ids\n",
        "for name in sorted(os.listdir(TEXT_DATA_DIR)):\n",
        "    path = os.path.join(TEXT_DATA_DIR, name)\n",
        "    if os.path.isdir(path):\n",
        "        label_id = len(labels_index)\n",
        "        labels_index[name] = label_id\n",
        "        for fname in sorted(os.listdir(path)):\n",
        "            if fname.isdigit():\n",
        "                fpath = os.path.join(path, fname)\n",
        "                if sys.version_info < (3,):\n",
        "                    f = open(fpath)\n",
        "                else:\n",
        "                    f = open(fpath, encoding='latin-1')\n",
        "                t = f.read()\n",
        "                i = t.find('\\n\\n')  # skip header\n",
        "                if 0 < i:\n",
        "                    t = t[i:]\n",
        "                texts.append(t)\n",
        "                f.close()\n",
        "                labels.append(label_id)\n",
        "\n",
        "print('Found %s texts.' % len(texts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLpxxEPqk-f1",
        "outputId": "88e9372c-0bcd-4d7e-be94-e3b3961d55fa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 19997 texts.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# MAX_NB_WORDS=1000\n",
        "MAX_SEQUENCE_LENGTH=1000\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "labels = to_categorical(np.asarray(labels))\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "# split the data into a training set and a validation set\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "VALIDATION_SPLIT=0.3\n",
        "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
        "\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_val = data[-nb_validation_samples:]\n",
        "y_val = labels[-nb_validation_samples:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x4fd2cvk-cC",
        "outputId": "ae2111bf-44f2-44b4-ae11-3ebc7f6faea4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 174074 unique tokens.\n",
            "Shape of data tensor: (19997, 1000)\n",
            "Shape of label tensor: (19997, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0r_4E8srvDl",
        "outputId": "d25c87c4-6709-4c32-a52c-3894d1f63f8a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-18 23:11:23--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-10-18 23:11:23--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-10-18 23:11:24--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.00MB/s    in 2m 42s  \n",
            "\n",
            "2022-10-18 23:14:07 (5.07 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lmhkARusdEh",
        "outputId": "02e73a12-4472-494a-813c-469a0c7b5909"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 3056064\n",
            "drwxr-xr-x 22 root root       4096 Oct 18 23:10 20_newsgroup\n",
            "drwxr-xr-x  1 root root       4096 Oct 17 13:44 sample_data\n",
            "-rw-r--r--  1 root root  862182613 Oct 25  2015 glove.6B.zip\n",
            "-rw-rw-r--  1 root root 1037962819 Aug 27  2014 glove.6B.300d.txt\n",
            "-rw-rw-r--  1 root root  171350079 Aug  4  2014 glove.6B.50d.txt\n",
            "-rw-rw-r--  1 root root  693432828 Aug  4  2014 glove.6B.200d.txt\n",
            "-rw-rw-r--  1 root root  347116733 Aug  4  2014 glove.6B.100d.txt\n",
            "-rw-r--r--  1 root root   17329808 Jan 30  2000 news20.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "GLOVE_DIR='/content'\n",
        "\n",
        "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsGLlwbok-Yi",
        "outputId": "437f297b-f08d-4fdf-d341-0fa6f6023b78"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM=100\n",
        "\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "vOZ8qglyk-Pu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(len(word_index) + 1,\n",
        "                            EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=False)"
      ],
      "metadata": {
        "id": "1k4wXWMLk-NT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Input\n",
        "from tensorflow.keras import Model"
      ],
      "metadata": {
        "id": "xdYJbLrvt8pz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeY8PORdzvHo",
        "outputId": "3eb8a5f2-cbc8-41d8-b9be-b3e1dfdabce3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
        "x = MaxPooling1D(5)(x)\n",
        "x = Conv1D(128, 5, activation='relu')(x)\n",
        "x = MaxPooling1D(5)(x)\n",
        "x = Conv1D(128, 5, activation='relu')(x)\n",
        "x = MaxPooling1D(35)(x)  # global max pooling\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "preds = Dense(len(labels_index), activation='softmax')(x)\n",
        "\n",
        "model = Model(sequence_input, preds)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['acc'])\n",
        "\n",
        "# happy learning!\n",
        "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=100, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Bp3crPAtRlA",
        "outputId": "5bb67d26-394b-4370-9f8e-9ef356555939"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "110/110 [==============================] - 4s 31ms/step - loss: 2.4454 - acc: 0.1977 - val_loss: 1.9164 - val_acc: 0.3206\n",
            "Epoch 2/100\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 1.6310 - acc: 0.4221 - val_loss: 1.4565 - val_acc: 0.4739\n",
            "Epoch 3/100\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 1.2567 - acc: 0.5642 - val_loss: 1.4082 - val_acc: 0.5194\n",
            "Epoch 4/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 1.0316 - acc: 0.6491 - val_loss: 1.2926 - val_acc: 0.5818\n",
            "Epoch 5/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.8775 - acc: 0.7062 - val_loss: 1.0513 - val_acc: 0.6453\n",
            "Epoch 6/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.7492 - acc: 0.7450 - val_loss: 1.0614 - val_acc: 0.6544\n",
            "Epoch 7/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.6499 - acc: 0.7799 - val_loss: 1.0329 - val_acc: 0.6723\n",
            "Epoch 8/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.5481 - acc: 0.8154 - val_loss: 1.0600 - val_acc: 0.6736\n",
            "Epoch 9/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.4711 - acc: 0.8417 - val_loss: 0.9646 - val_acc: 0.6978\n",
            "Epoch 10/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.3988 - acc: 0.8671 - val_loss: 1.0135 - val_acc: 0.7026\n",
            "Epoch 11/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.3379 - acc: 0.8881 - val_loss: 1.2276 - val_acc: 0.6791\n",
            "Epoch 12/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.2873 - acc: 0.9035 - val_loss: 1.1851 - val_acc: 0.6936\n",
            "Epoch 13/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.2528 - acc: 0.9178 - val_loss: 1.1062 - val_acc: 0.7146\n",
            "Epoch 14/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.2205 - acc: 0.9288 - val_loss: 1.0745 - val_acc: 0.7295\n",
            "Epoch 15/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.1973 - acc: 0.9379 - val_loss: 1.4124 - val_acc: 0.6764\n",
            "Epoch 16/100\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 0.1975 - acc: 0.9373 - val_loss: 1.1224 - val_acc: 0.7198\n",
            "Epoch 17/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.1734 - acc: 0.9451 - val_loss: 1.0571 - val_acc: 0.7330\n",
            "Epoch 18/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.1508 - acc: 0.9518 - val_loss: 1.7658 - val_acc: 0.6573\n",
            "Epoch 19/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.1533 - acc: 0.9493 - val_loss: 1.1795 - val_acc: 0.7368\n",
            "Epoch 20/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.1595 - acc: 0.9514 - val_loss: 1.2085 - val_acc: 0.7310\n",
            "Epoch 21/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.1444 - acc: 0.9558 - val_loss: 1.2368 - val_acc: 0.7225\n",
            "Epoch 22/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.1401 - acc: 0.9564 - val_loss: 1.2261 - val_acc: 0.7303\n",
            "Epoch 23/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.1290 - acc: 0.9572 - val_loss: 2.7112 - val_acc: 0.5603\n",
            "Epoch 24/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.1359 - acc: 0.9577 - val_loss: 1.4765 - val_acc: 0.6991\n",
            "Epoch 25/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.1123 - acc: 0.9605 - val_loss: 1.4325 - val_acc: 0.7335\n",
            "Epoch 26/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.1416 - acc: 0.9553 - val_loss: 1.2673 - val_acc: 0.7303\n",
            "Epoch 27/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.1127 - acc: 0.9603 - val_loss: 1.5602 - val_acc: 0.7096\n",
            "Epoch 28/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.1112 - acc: 0.9631 - val_loss: 1.7041 - val_acc: 0.6708\n",
            "Epoch 29/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.1127 - acc: 0.9609 - val_loss: 1.3073 - val_acc: 0.7253\n",
            "Epoch 30/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.1062 - acc: 0.9626 - val_loss: 1.8307 - val_acc: 0.6763\n",
            "Epoch 31/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.1004 - acc: 0.9649 - val_loss: 1.2620 - val_acc: 0.7363\n",
            "Epoch 32/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.0986 - acc: 0.9646 - val_loss: 1.7517 - val_acc: 0.7018\n",
            "Epoch 33/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0944 - acc: 0.9654 - val_loss: 2.0239 - val_acc: 0.6746\n",
            "Epoch 34/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0993 - acc: 0.9633 - val_loss: 2.1090 - val_acc: 0.6964\n",
            "Epoch 35/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.1016 - acc: 0.9633 - val_loss: 1.5172 - val_acc: 0.7043\n",
            "Epoch 36/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0883 - acc: 0.9647 - val_loss: 1.4503 - val_acc: 0.7373\n",
            "Epoch 37/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.0845 - acc: 0.9659 - val_loss: 1.5452 - val_acc: 0.7308\n",
            "Epoch 38/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0858 - acc: 0.9672 - val_loss: 1.5390 - val_acc: 0.7230\n",
            "Epoch 39/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0870 - acc: 0.9666 - val_loss: 1.9020 - val_acc: 0.6831\n",
            "Epoch 40/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0847 - acc: 0.9654 - val_loss: 1.9040 - val_acc: 0.7053\n",
            "Epoch 41/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.0772 - acc: 0.9659 - val_loss: 1.7066 - val_acc: 0.7236\n",
            "Epoch 42/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.0795 - acc: 0.9676 - val_loss: 1.7418 - val_acc: 0.7203\n",
            "Epoch 43/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.0716 - acc: 0.9676 - val_loss: 1.7954 - val_acc: 0.7213\n",
            "Epoch 44/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.0756 - acc: 0.9676 - val_loss: 1.7798 - val_acc: 0.7238\n",
            "Epoch 45/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.0759 - acc: 0.9674 - val_loss: 1.7009 - val_acc: 0.7240\n",
            "Epoch 46/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0746 - acc: 0.9673 - val_loss: 1.8895 - val_acc: 0.7253\n",
            "Epoch 47/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.0793 - acc: 0.9664 - val_loss: 1.7654 - val_acc: 0.7293\n",
            "Epoch 48/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.0707 - acc: 0.9687 - val_loss: 1.6628 - val_acc: 0.7311\n",
            "Epoch 49/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0681 - acc: 0.9687 - val_loss: 1.8930 - val_acc: 0.7080\n",
            "Epoch 50/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0718 - acc: 0.9682 - val_loss: 2.2384 - val_acc: 0.7031\n",
            "Epoch 51/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0774 - acc: 0.9668 - val_loss: 1.8960 - val_acc: 0.7355\n",
            "Epoch 52/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.0746 - acc: 0.9675 - val_loss: 1.8445 - val_acc: 0.7218\n",
            "Epoch 53/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0764 - acc: 0.9691 - val_loss: 1.9413 - val_acc: 0.7256\n",
            "Epoch 54/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.0705 - acc: 0.9674 - val_loss: 2.0538 - val_acc: 0.7306\n",
            "Epoch 55/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0698 - acc: 0.9692 - val_loss: 2.0185 - val_acc: 0.6929\n",
            "Epoch 56/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.0694 - acc: 0.9664 - val_loss: 2.0566 - val_acc: 0.7055\n",
            "Epoch 57/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.0709 - acc: 0.9660 - val_loss: 2.0532 - val_acc: 0.7305\n",
            "Epoch 58/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.0759 - acc: 0.9684 - val_loss: 3.0280 - val_acc: 0.6623\n",
            "Epoch 59/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.0720 - acc: 0.9676 - val_loss: 2.9213 - val_acc: 0.7066\n",
            "Epoch 60/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.0672 - acc: 0.9697 - val_loss: 2.2272 - val_acc: 0.6611\n",
            "Epoch 61/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0684 - acc: 0.9689 - val_loss: 2.2341 - val_acc: 0.7278\n",
            "Epoch 62/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.0728 - acc: 0.9693 - val_loss: 1.8233 - val_acc: 0.7146\n",
            "Epoch 63/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.0622 - acc: 0.9712 - val_loss: 2.2867 - val_acc: 0.7328\n",
            "Epoch 64/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.0675 - acc: 0.9690 - val_loss: 2.5462 - val_acc: 0.7320\n",
            "Epoch 65/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.0717 - acc: 0.9675 - val_loss: 2.1691 - val_acc: 0.7285\n",
            "Epoch 66/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.0730 - acc: 0.9661 - val_loss: 2.3453 - val_acc: 0.7250\n",
            "Epoch 67/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0639 - acc: 0.9696 - val_loss: 2.7950 - val_acc: 0.7240\n",
            "Epoch 68/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0703 - acc: 0.9684 - val_loss: 2.0595 - val_acc: 0.7305\n",
            "Epoch 69/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.0655 - acc: 0.9690 - val_loss: 2.9729 - val_acc: 0.7253\n",
            "Epoch 70/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.0680 - acc: 0.9683 - val_loss: 3.4397 - val_acc: 0.7166\n",
            "Epoch 71/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.0781 - acc: 0.9679 - val_loss: 2.4114 - val_acc: 0.7318\n",
            "Epoch 72/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0654 - acc: 0.9696 - val_loss: 4.4625 - val_acc: 0.6689\n",
            "Epoch 73/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0975 - acc: 0.9643 - val_loss: 2.2106 - val_acc: 0.7253\n",
            "Epoch 74/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.0614 - acc: 0.9706 - val_loss: 3.1251 - val_acc: 0.7233\n",
            "Epoch 75/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0704 - acc: 0.9692 - val_loss: 2.9502 - val_acc: 0.7266\n",
            "Epoch 76/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.0730 - acc: 0.9680 - val_loss: 2.4418 - val_acc: 0.7126\n",
            "Epoch 77/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0642 - acc: 0.9687 - val_loss: 2.4734 - val_acc: 0.7231\n",
            "Epoch 78/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0840 - acc: 0.9679 - val_loss: 2.8865 - val_acc: 0.7200\n",
            "Epoch 79/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.0706 - acc: 0.9702 - val_loss: 2.9727 - val_acc: 0.7315\n",
            "Epoch 80/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.0607 - acc: 0.9699 - val_loss: 2.9588 - val_acc: 0.7266\n",
            "Epoch 81/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0708 - acc: 0.9678 - val_loss: 3.0054 - val_acc: 0.6793\n",
            "Epoch 82/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.0692 - acc: 0.9699 - val_loss: 2.7921 - val_acc: 0.7230\n",
            "Epoch 83/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0791 - acc: 0.9703 - val_loss: 2.8589 - val_acc: 0.7288\n",
            "Epoch 84/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.0643 - acc: 0.9699 - val_loss: 4.0264 - val_acc: 0.7296\n",
            "Epoch 85/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0756 - acc: 0.9689 - val_loss: 3.1204 - val_acc: 0.7261\n",
            "Epoch 86/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0805 - acc: 0.9696 - val_loss: 2.6591 - val_acc: 0.7206\n",
            "Epoch 87/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0648 - acc: 0.9694 - val_loss: 3.1477 - val_acc: 0.7175\n",
            "Epoch 88/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.0745 - acc: 0.9686 - val_loss: 2.8247 - val_acc: 0.7293\n",
            "Epoch 89/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0656 - acc: 0.9687 - val_loss: 3.0498 - val_acc: 0.7345\n",
            "Epoch 90/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0666 - acc: 0.9694 - val_loss: 2.5256 - val_acc: 0.7258\n",
            "Epoch 91/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0835 - acc: 0.9691 - val_loss: 3.7421 - val_acc: 0.7238\n",
            "Epoch 92/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0694 - acc: 0.9689 - val_loss: 2.9609 - val_acc: 0.7205\n",
            "Epoch 93/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.0651 - acc: 0.9711 - val_loss: 4.5176 - val_acc: 0.7263\n",
            "Epoch 94/100\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.0743 - acc: 0.9680 - val_loss: 2.6924 - val_acc: 0.7251\n",
            "Epoch 95/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.0756 - acc: 0.9690 - val_loss: 4.0569 - val_acc: 0.7186\n",
            "Epoch 96/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.0789 - acc: 0.9678 - val_loss: 3.8294 - val_acc: 0.6978\n",
            "Epoch 97/100\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.0777 - acc: 0.9689 - val_loss: 3.0956 - val_acc: 0.7185\n",
            "Epoch 98/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.0728 - acc: 0.9691 - val_loss: 3.1295 - val_acc: 0.7151\n",
            "Epoch 99/100\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.0663 - acc: 0.9695 - val_loss: 3.4405 - val_acc: 0.7225\n",
            "Epoch 100/100\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 0.0805 - acc: 0.9673 - val_loss: 3.5719 - val_acc: 0.7286\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7900fd43d0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hvjInEnktSBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# coding: utf-8\n",
        "\n",
        "# # 20 Newsgroups text classification with pre-trained word embeddings\n",
        "# \n",
        "# In this script, we'll use pre-trained [GloVe word embeddings]\n",
        "# (http://nlp.stanford.edu/projects/glove/) for text classification\n",
        "# using Keras (version $\\ge$ 2 is required). This script is largely\n",
        "# based on the blog post [Using pre-trained word embeddings in a Keras\n",
        "# model]\n",
        "# (https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html)\n",
        "# by François Chollet.\n",
        "# \n",
        "# **Note that using a GPU with this script is highly recommended.**\n",
        "# \n",
        "# First, the needed imports. Keras tells us which backend (Theano,\n",
        "# Tensorflow, CNTK) it will be using.\n",
        "\n",
        "from keras.preprocessing import sequence, text\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "from keras.layers import LSTM, CuDNNLSTM\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from distutils.version import LooseVersion as LV\n",
        "from keras import __version__\n",
        "from keras import backend as K\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print('Using Keras version:', __version__, 'backend:', K.backend())\n",
        "assert(LV(__version__) >= LV(\"2.0.0\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jSnOO9_k-J4",
        "outputId": "ac851d78-1445-4192-ee4f-61f780d85029"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Keras version: 2.9.0 backend: tensorflow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GLOVE_DIR = \"/content\"\n",
        "\n",
        "print('Indexing word vectors.')\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt')) as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n",
        "    # ## GloVe word embeddings\n",
        "    # \n",
        "    # Let's begin by loading a datafile containing pre-trained word\n",
        "    # embeddings.  The datafile contains 100-dimensional embeddings for\n",
        "    # 400,000 English words.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNB4VpHA2udc",
        "outputId": "70a59362-b024-4060-fd71-a3e0329a83ed"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indexing word vectors.\n",
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT_DATA_DIR = \"/content/20_newsgroup\"\n",
        "\n",
        "print('Processing text dataset')\n",
        "\n",
        "texts = []  # list of text samples\n",
        "labels_index = {}  # dictionary mapping label name to numeric id\n",
        "labels = []  # list of label ids\n",
        "for name in sorted(os.listdir(TEXT_DATA_DIR)):\n",
        "    path = os.path.join(TEXT_DATA_DIR, name)\n",
        "    if os.path.isdir(path):\n",
        "        label_id = len(labels_index)\n",
        "        labels_index[name] = label_id\n",
        "        for fname in sorted(os.listdir(path)):\n",
        "            if fname.isdigit():\n",
        "                fpath = os.path.join(path, fname)\n",
        "                args = {} if sys.version_info < (3,) else {'encoding': 'latin-1'}\n",
        "                with open(fpath, **args) as f:\n",
        "                    t = f.read()\n",
        "                    i = t.find('\\n\\n')  # skip header\n",
        "                    if 0 < i:\n",
        "                        t = t[i:]\n",
        "                    texts.append(t)\n",
        "                labels.append(label_id)\n",
        "\n",
        "print('Found %s texts.' % len(texts))\n",
        "# ## 20 Newsgroups data set\n",
        "    # \n",
        "    # Next we'll load the [20 Newsgroups]\n",
        "    # (http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.html)\n",
        "    # data set.\n",
        "    # \n",
        "    # The dataset contains 20000 messages collected from 20 different\n",
        "    # Usenet newsgroups (1000 messages from each group):\n",
        "    # \n",
        "    # alt.atheism           | soc.religion.christian   | comp.windows.x     | sci.crypt   \n",
        "    # talk.politics.guns    | comp.sys.ibm.pc.hardware | rec.autos          | sci.electronics\n",
        "    # talk.politics.mideast | comp.graphics            | rec.motorcycles    | sci.space\n",
        "    # talk.politics.misc    | comp.os.ms-windows.misc  | rec.sport.baseball | sci.med\n",
        "    # talk.religion.misc    | comp.sys.mac.hardware    | rec.sport.hockey   | misc.forsale"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDoiCglL2utu",
        "outputId": "daf72101-2005-41f1-af80-9e7bfc3cd05c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing text dataset\n",
            "Found 19997 texts.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the text samples into a 2D integer tensor.\n",
        "\n",
        "MAX_NUM_WORDS = 10000\n",
        "MAX_SEQUENCE_LENGTH = 1000 \n",
        "\n",
        "tokenizer = text.Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "labels = to_categorical(np.asarray(labels))\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "# Split the data into a training set and a validation set\n",
        "\n",
        "VALIDATION_SET, TEST_SET = 1000, 4000\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, labels, \n",
        "                                                    test_size=TEST_SET,\n",
        "                                                    shuffle=True, random_state=42)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, \n",
        "                                                  test_size=VALIDATION_SET,\n",
        "                                                  shuffle=False)\n",
        "\n",
        "print('Shape of training data tensor:', x_train.shape)\n",
        "print('Shape of training label tensor:', y_train.shape)\n",
        "print('Shape of validation data tensor:', x_val.shape)\n",
        "print('Shape of validation label tensor:', y_val.shape)\n",
        "print('Shape of test data tensor:', x_test.shape)\n",
        "print('Shape of test label tensor:', y_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTTeEatV3Wzh",
        "outputId": "3b4efb4d-93e9-4644-d8c4-25a8bb02b41e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 174074 unique tokens.\n",
            "Shape of data tensor: (19997, 1000)\n",
            "Shape of label tensor: (19997, 20)\n",
            "Shape of training data tensor: (14997, 1000)\n",
            "Shape of training label tensor: (14997, 20)\n",
            "Shape of validation data tensor: (1000, 1000)\n",
            "Shape of validation label tensor: (1000, 20)\n",
            "Shape of test data tensor: (4000, 1000)\n",
            "Shape of test label tensor: (4000, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the embedding matrix:\n",
        "\n",
        "print('Preparing embedding matrix.')\n",
        "\n",
        "num_words = min(MAX_NUM_WORDS, len(word_index) + 1)\n",
        "embedding_dim = 100\n",
        "\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i >= MAX_NUM_WORDS:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "print('Shape of embedding matrix:', embedding_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TU90pwG3W_X",
        "outputId": "752cafce-460d-4d16-edda-31f1ed61d239"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing embedding matrix.\n",
            "Shape of embedding matrix: (10000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ### Initialization\n",
        "\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(num_words,\n",
        "                    embedding_dim,\n",
        "                    weights=[embedding_matrix],\n",
        "                    input_length=MAX_SEQUENCE_LENGTH,\n",
        "                    trainable=False))\n",
        "#model.add(Dropout(0.2))\n",
        "\n",
        "model.add(CuDNNLSTM(128))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(20, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# ### Learning\n",
        "\n",
        "epochs = 100\n",
        "batch_size=128\n",
        "\n",
        "json_logging_callback = LambdaCallback(\n",
        "    on_epoch_end=lambda epoch, logs: print(json.dumps({\n",
        "        \"epoch\": epoch,\n",
        "        \"loss\": logs[\"loss\"],\n",
        "\n",
        "        \"val_loss\": logs[\"val_loss\"],\n",
        "\n",
        "    })),\n",
        ")\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=2, callbacks=[json_logging_callback])\n",
        "\n",
        "model.save('20ng-rnn.h5')\n",
        "#         \"acc\": logs[\"acc\"],\n",
        "        # \"val_acc\": logs[\"val_acc\"],"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-3y_kCw4tPV",
        "outputId": "07835232-ee36-4a47-da6b-c836cee739d4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build model...\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 1000, 100)         1000000   \n",
            "                                                                 \n",
            " cu_dnnlstm_3 (CuDNNLSTM)    (None, 128)               117760    \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 20)                2580      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,136,852\n",
            "Trainable params: 136,852\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "{\"epoch\": 0, \"loss\": 2.723501682281494, \"val_loss\": 2.439005136489868}\n",
            "118/118 - 9s - loss: 2.7235 - accuracy: 0.1578 - val_loss: 2.4390 - val_accuracy: 0.1930 - 9s/epoch - 77ms/step\n",
            "Epoch 2/100\n",
            "{\"epoch\": 1, \"loss\": 2.258535623550415, \"val_loss\": 2.3215668201446533}\n",
            "118/118 - 7s - loss: 2.2585 - accuracy: 0.2544 - val_loss: 2.3216 - val_accuracy: 0.2160 - 7s/epoch - 62ms/step\n",
            "Epoch 3/100\n",
            "{\"epoch\": 2, \"loss\": 1.9535300731658936, \"val_loss\": 2.317683696746826}\n",
            "118/118 - 7s - loss: 1.9535 - accuracy: 0.3518 - val_loss: 2.3177 - val_accuracy: 0.2490 - 7s/epoch - 62ms/step\n",
            "Epoch 4/100\n",
            "{\"epoch\": 3, \"loss\": 1.6937861442565918, \"val_loss\": 1.6558232307434082}\n",
            "118/118 - 7s - loss: 1.6938 - accuracy: 0.4311 - val_loss: 1.6558 - val_accuracy: 0.4390 - 7s/epoch - 62ms/step\n",
            "Epoch 5/100\n",
            "{\"epoch\": 4, \"loss\": 1.4550398588180542, \"val_loss\": 1.7187373638153076}\n",
            "118/118 - 7s - loss: 1.4550 - accuracy: 0.5100 - val_loss: 1.7187 - val_accuracy: 0.4310 - 7s/epoch - 62ms/step\n",
            "Epoch 6/100\n",
            "{\"epoch\": 5, \"loss\": 1.275602102279663, \"val_loss\": 1.3210114240646362}\n",
            "118/118 - 7s - loss: 1.2756 - accuracy: 0.5671 - val_loss: 1.3210 - val_accuracy: 0.5610 - 7s/epoch - 62ms/step\n",
            "Epoch 7/100\n",
            "{\"epoch\": 6, \"loss\": 1.1453802585601807, \"val_loss\": 1.3412721157073975}\n",
            "118/118 - 7s - loss: 1.1454 - accuracy: 0.6094 - val_loss: 1.3413 - val_accuracy: 0.5490 - 7s/epoch - 62ms/step\n",
            "Epoch 8/100\n",
            "{\"epoch\": 7, \"loss\": 1.0294609069824219, \"val_loss\": 1.4501996040344238}\n",
            "118/118 - 7s - loss: 1.0295 - accuracy: 0.6506 - val_loss: 1.4502 - val_accuracy: 0.5180 - 7s/epoch - 62ms/step\n",
            "Epoch 9/100\n",
            "{\"epoch\": 8, \"loss\": 0.940003514289856, \"val_loss\": 1.219695806503296}\n",
            "118/118 - 7s - loss: 0.9400 - accuracy: 0.6826 - val_loss: 1.2197 - val_accuracy: 0.5820 - 7s/epoch - 62ms/step\n",
            "Epoch 10/100\n",
            "{\"epoch\": 9, \"loss\": 0.8561694025993347, \"val_loss\": 1.1545403003692627}\n",
            "118/118 - 8s - loss: 0.8562 - accuracy: 0.7112 - val_loss: 1.1545 - val_accuracy: 0.6270 - 8s/epoch - 66ms/step\n",
            "Epoch 11/100\n",
            "{\"epoch\": 10, \"loss\": 0.7896259427070618, \"val_loss\": 1.1053353548049927}\n",
            "118/118 - 8s - loss: 0.7896 - accuracy: 0.7324 - val_loss: 1.1053 - val_accuracy: 0.6230 - 8s/epoch - 66ms/step\n",
            "Epoch 12/100\n",
            "{\"epoch\": 11, \"loss\": 0.7288463711738586, \"val_loss\": 1.1164460182189941}\n",
            "118/118 - 7s - loss: 0.7288 - accuracy: 0.7542 - val_loss: 1.1164 - val_accuracy: 0.6710 - 7s/epoch - 62ms/step\n",
            "Epoch 13/100\n",
            "{\"epoch\": 12, \"loss\": 0.6693459153175354, \"val_loss\": 1.1434861421585083}\n",
            "118/118 - 7s - loss: 0.6693 - accuracy: 0.7754 - val_loss: 1.1435 - val_accuracy: 0.6180 - 7s/epoch - 62ms/step\n",
            "Epoch 14/100\n",
            "{\"epoch\": 13, \"loss\": 0.6169598698616028, \"val_loss\": 1.2551554441452026}\n",
            "118/118 - 7s - loss: 0.6170 - accuracy: 0.7916 - val_loss: 1.2552 - val_accuracy: 0.6280 - 7s/epoch - 62ms/step\n",
            "Epoch 15/100\n",
            "{\"epoch\": 14, \"loss\": 0.5666376948356628, \"val_loss\": 1.1575945615768433}\n",
            "118/118 - 7s - loss: 0.5666 - accuracy: 0.8078 - val_loss: 1.1576 - val_accuracy: 0.6560 - 7s/epoch - 62ms/step\n",
            "Epoch 16/100\n",
            "{\"epoch\": 15, \"loss\": 0.5149351954460144, \"val_loss\": 1.0704768896102905}\n",
            "118/118 - 7s - loss: 0.5149 - accuracy: 0.8238 - val_loss: 1.0705 - val_accuracy: 0.6710 - 7s/epoch - 62ms/step\n",
            "Epoch 17/100\n",
            "{\"epoch\": 16, \"loss\": 0.4738079011440277, \"val_loss\": 1.1650538444519043}\n",
            "118/118 - 7s - loss: 0.4738 - accuracy: 0.8376 - val_loss: 1.1651 - val_accuracy: 0.6530 - 7s/epoch - 62ms/step\n",
            "Epoch 18/100\n",
            "{\"epoch\": 17, \"loss\": 0.43197333812713623, \"val_loss\": 1.1121106147766113}\n",
            "118/118 - 7s - loss: 0.4320 - accuracy: 0.8501 - val_loss: 1.1121 - val_accuracy: 0.6660 - 7s/epoch - 62ms/step\n",
            "Epoch 19/100\n",
            "{\"epoch\": 18, \"loss\": 0.3952536880970001, \"val_loss\": 1.2073005437850952}\n",
            "118/118 - 7s - loss: 0.3953 - accuracy: 0.8620 - val_loss: 1.2073 - val_accuracy: 0.6470 - 7s/epoch - 62ms/step\n",
            "Epoch 20/100\n",
            "{\"epoch\": 19, \"loss\": 0.35276156663894653, \"val_loss\": 1.1183453798294067}\n",
            "118/118 - 7s - loss: 0.3528 - accuracy: 0.8772 - val_loss: 1.1183 - val_accuracy: 0.6910 - 7s/epoch - 62ms/step\n",
            "Epoch 21/100\n",
            "{\"epoch\": 20, \"loss\": 0.3223249018192291, \"val_loss\": 1.2159640789031982}\n",
            "118/118 - 7s - loss: 0.3223 - accuracy: 0.8880 - val_loss: 1.2160 - val_accuracy: 0.6850 - 7s/epoch - 62ms/step\n",
            "Epoch 22/100\n",
            "{\"epoch\": 21, \"loss\": 0.29326415061950684, \"val_loss\": 1.2286792993545532}\n",
            "118/118 - 7s - loss: 0.2933 - accuracy: 0.8974 - val_loss: 1.2287 - val_accuracy: 0.6840 - 7s/epoch - 62ms/step\n",
            "Epoch 23/100\n",
            "{\"epoch\": 22, \"loss\": 0.26481693983078003, \"val_loss\": 1.153041124343872}\n",
            "118/118 - 7s - loss: 0.2648 - accuracy: 0.9084 - val_loss: 1.1530 - val_accuracy: 0.6920 - 7s/epoch - 62ms/step\n",
            "Epoch 24/100\n",
            "{\"epoch\": 23, \"loss\": 0.23774033784866333, \"val_loss\": 1.3847090005874634}\n",
            "118/118 - 7s - loss: 0.2377 - accuracy: 0.9179 - val_loss: 1.3847 - val_accuracy: 0.6670 - 7s/epoch - 62ms/step\n",
            "Epoch 25/100\n",
            "{\"epoch\": 24, \"loss\": 0.2236335575580597, \"val_loss\": 1.2192045450210571}\n",
            "118/118 - 7s - loss: 0.2236 - accuracy: 0.9205 - val_loss: 1.2192 - val_accuracy: 0.7000 - 7s/epoch - 62ms/step\n",
            "Epoch 26/100\n",
            "{\"epoch\": 25, \"loss\": 0.19883643090724945, \"val_loss\": 1.2626690864562988}\n",
            "118/118 - 7s - loss: 0.1988 - accuracy: 0.9307 - val_loss: 1.2627 - val_accuracy: 0.6840 - 7s/epoch - 62ms/step\n",
            "Epoch 27/100\n",
            "{\"epoch\": 26, \"loss\": 0.1824619024991989, \"val_loss\": 1.246115803718567}\n",
            "118/118 - 8s - loss: 0.1825 - accuracy: 0.9364 - val_loss: 1.2461 - val_accuracy: 0.7020 - 8s/epoch - 65ms/step\n",
            "Epoch 28/100\n",
            "{\"epoch\": 27, \"loss\": 0.16534902155399323, \"val_loss\": 1.4775497913360596}\n",
            "118/118 - 7s - loss: 0.1653 - accuracy: 0.9429 - val_loss: 1.4775 - val_accuracy: 0.6690 - 7s/epoch - 62ms/step\n",
            "Epoch 29/100\n",
            "{\"epoch\": 28, \"loss\": 0.15490663051605225, \"val_loss\": 1.4527901411056519}\n",
            "118/118 - 7s - loss: 0.1549 - accuracy: 0.9453 - val_loss: 1.4528 - val_accuracy: 0.6830 - 7s/epoch - 62ms/step\n",
            "Epoch 30/100\n",
            "{\"epoch\": 29, \"loss\": 0.1419532746076584, \"val_loss\": 1.36716890335083}\n",
            "118/118 - 7s - loss: 0.1420 - accuracy: 0.9505 - val_loss: 1.3672 - val_accuracy: 0.7060 - 7s/epoch - 63ms/step\n",
            "Epoch 31/100\n",
            "{\"epoch\": 30, \"loss\": 0.13722285628318787, \"val_loss\": 1.3800678253173828}\n",
            "118/118 - 7s - loss: 0.1372 - accuracy: 0.9516 - val_loss: 1.3801 - val_accuracy: 0.7100 - 7s/epoch - 62ms/step\n",
            "Epoch 32/100\n",
            "{\"epoch\": 31, \"loss\": 0.1283448189496994, \"val_loss\": 1.4530434608459473}\n",
            "118/118 - 7s - loss: 0.1283 - accuracy: 0.9535 - val_loss: 1.4530 - val_accuracy: 0.6970 - 7s/epoch - 63ms/step\n",
            "Epoch 33/100\n",
            "{\"epoch\": 32, \"loss\": 0.12621937692165375, \"val_loss\": 1.4530352354049683}\n",
            "118/118 - 7s - loss: 0.1262 - accuracy: 0.9551 - val_loss: 1.4530 - val_accuracy: 0.6940 - 7s/epoch - 63ms/step\n",
            "Epoch 34/100\n",
            "{\"epoch\": 33, \"loss\": 0.12005199491977692, \"val_loss\": 1.4669649600982666}\n",
            "118/118 - 7s - loss: 0.1201 - accuracy: 0.9573 - val_loss: 1.4670 - val_accuracy: 0.6900 - 7s/epoch - 62ms/step\n",
            "Epoch 35/100\n",
            "{\"epoch\": 34, \"loss\": 0.11252681910991669, \"val_loss\": 1.536043405532837}\n",
            "118/118 - 7s - loss: 0.1125 - accuracy: 0.9596 - val_loss: 1.5360 - val_accuracy: 0.7120 - 7s/epoch - 62ms/step\n",
            "Epoch 36/100\n",
            "{\"epoch\": 35, \"loss\": 0.11162928491830826, \"val_loss\": 1.5577589273452759}\n",
            "118/118 - 7s - loss: 0.1116 - accuracy: 0.9589 - val_loss: 1.5578 - val_accuracy: 0.7000 - 7s/epoch - 62ms/step\n",
            "Epoch 37/100\n",
            "{\"epoch\": 36, \"loss\": 0.10476230829954147, \"val_loss\": 1.685487151145935}\n",
            "118/118 - 7s - loss: 0.1048 - accuracy: 0.9615 - val_loss: 1.6855 - val_accuracy: 0.6820 - 7s/epoch - 62ms/step\n",
            "Epoch 38/100\n",
            "{\"epoch\": 37, \"loss\": 0.10274951905012131, \"val_loss\": 1.5534037351608276}\n",
            "118/118 - 7s - loss: 0.1027 - accuracy: 0.9619 - val_loss: 1.5534 - val_accuracy: 0.7000 - 7s/epoch - 62ms/step\n",
            "Epoch 39/100\n",
            "{\"epoch\": 38, \"loss\": 0.10135839134454727, \"val_loss\": 1.553447961807251}\n",
            "118/118 - 7s - loss: 0.1014 - accuracy: 0.9628 - val_loss: 1.5534 - val_accuracy: 0.6960 - 7s/epoch - 62ms/step\n",
            "Epoch 40/100\n",
            "{\"epoch\": 39, \"loss\": 0.09921647608280182, \"val_loss\": 1.6092569828033447}\n",
            "118/118 - 7s - loss: 0.0992 - accuracy: 0.9612 - val_loss: 1.6093 - val_accuracy: 0.6930 - 7s/epoch - 62ms/step\n",
            "Epoch 41/100\n",
            "{\"epoch\": 40, \"loss\": 0.09322842210531235, \"val_loss\": 1.63471519947052}\n",
            "118/118 - 7s - loss: 0.0932 - accuracy: 0.9647 - val_loss: 1.6347 - val_accuracy: 0.7040 - 7s/epoch - 62ms/step\n",
            "Epoch 42/100\n",
            "{\"epoch\": 41, \"loss\": 0.09210409969091415, \"val_loss\": 1.6080379486083984}\n",
            "118/118 - 7s - loss: 0.0921 - accuracy: 0.9626 - val_loss: 1.6080 - val_accuracy: 0.7030 - 7s/epoch - 62ms/step\n",
            "Epoch 43/100\n",
            "{\"epoch\": 42, \"loss\": 0.09321478754281998, \"val_loss\": 1.6860442161560059}\n",
            "118/118 - 7s - loss: 0.0932 - accuracy: 0.9632 - val_loss: 1.6860 - val_accuracy: 0.6870 - 7s/epoch - 62ms/step\n",
            "Epoch 44/100\n",
            "{\"epoch\": 43, \"loss\": 0.08940497040748596, \"val_loss\": 1.6877044439315796}\n",
            "118/118 - 8s - loss: 0.0894 - accuracy: 0.9635 - val_loss: 1.6877 - val_accuracy: 0.7030 - 8s/epoch - 64ms/step\n",
            "Epoch 45/100\n",
            "{\"epoch\": 44, \"loss\": 0.08869361132383347, \"val_loss\": 1.7301204204559326}\n",
            "118/118 - 7s - loss: 0.0887 - accuracy: 0.9661 - val_loss: 1.7301 - val_accuracy: 0.6880 - 7s/epoch - 62ms/step\n",
            "Epoch 46/100\n",
            "{\"epoch\": 45, \"loss\": 0.087016761302948, \"val_loss\": 1.7345651388168335}\n",
            "118/118 - 7s - loss: 0.0870 - accuracy: 0.9653 - val_loss: 1.7346 - val_accuracy: 0.6870 - 7s/epoch - 62ms/step\n",
            "Epoch 47/100\n",
            "{\"epoch\": 46, \"loss\": 0.08366753160953522, \"val_loss\": 1.700882077217102}\n",
            "118/118 - 7s - loss: 0.0837 - accuracy: 0.9661 - val_loss: 1.7009 - val_accuracy: 0.7090 - 7s/epoch - 62ms/step\n",
            "Epoch 48/100\n",
            "{\"epoch\": 47, \"loss\": 0.08354029059410095, \"val_loss\": 1.7407522201538086}\n",
            "118/118 - 7s - loss: 0.0835 - accuracy: 0.9651 - val_loss: 1.7408 - val_accuracy: 0.6970 - 7s/epoch - 61ms/step\n",
            "Epoch 49/100\n",
            "{\"epoch\": 48, \"loss\": 0.08332690596580505, \"val_loss\": 1.905100703239441}\n",
            "118/118 - 7s - loss: 0.0833 - accuracy: 0.9659 - val_loss: 1.9051 - val_accuracy: 0.6790 - 7s/epoch - 61ms/step\n",
            "Epoch 50/100\n",
            "{\"epoch\": 49, \"loss\": 0.08394332230091095, \"val_loss\": 1.7925550937652588}\n",
            "118/118 - 7s - loss: 0.0839 - accuracy: 0.9657 - val_loss: 1.7926 - val_accuracy: 0.6930 - 7s/epoch - 62ms/step\n",
            "Epoch 51/100\n",
            "{\"epoch\": 50, \"loss\": 0.08048279583454132, \"val_loss\": 1.73164963722229}\n",
            "118/118 - 7s - loss: 0.0805 - accuracy: 0.9663 - val_loss: 1.7316 - val_accuracy: 0.6840 - 7s/epoch - 62ms/step\n",
            "Epoch 52/100\n",
            "{\"epoch\": 51, \"loss\": 0.0777454823255539, \"val_loss\": 1.724179983139038}\n",
            "118/118 - 7s - loss: 0.0777 - accuracy: 0.9675 - val_loss: 1.7242 - val_accuracy: 0.7020 - 7s/epoch - 62ms/step\n",
            "Epoch 53/100\n",
            "{\"epoch\": 52, \"loss\": 0.07853329926729202, \"val_loss\": 1.8042548894882202}\n",
            "118/118 - 7s - loss: 0.0785 - accuracy: 0.9673 - val_loss: 1.8043 - val_accuracy: 0.6890 - 7s/epoch - 62ms/step\n",
            "Epoch 54/100\n",
            "{\"epoch\": 53, \"loss\": 0.07645124942064285, \"val_loss\": 1.772113561630249}\n",
            "118/118 - 7s - loss: 0.0765 - accuracy: 0.9667 - val_loss: 1.7721 - val_accuracy: 0.6980 - 7s/epoch - 62ms/step\n",
            "Epoch 55/100\n",
            "{\"epoch\": 54, \"loss\": 0.07800643146038055, \"val_loss\": 1.8483085632324219}\n",
            "118/118 - 7s - loss: 0.0780 - accuracy: 0.9671 - val_loss: 1.8483 - val_accuracy: 0.6940 - 7s/epoch - 62ms/step\n",
            "Epoch 56/100\n",
            "{\"epoch\": 55, \"loss\": 0.07477186620235443, \"val_loss\": 1.8585855960845947}\n",
            "118/118 - 7s - loss: 0.0748 - accuracy: 0.9679 - val_loss: 1.8586 - val_accuracy: 0.7030 - 7s/epoch - 62ms/step\n",
            "Epoch 57/100\n",
            "{\"epoch\": 56, \"loss\": 0.07502014935016632, \"val_loss\": 1.8223234415054321}\n",
            "118/118 - 7s - loss: 0.0750 - accuracy: 0.9670 - val_loss: 1.8223 - val_accuracy: 0.6970 - 7s/epoch - 62ms/step\n",
            "Epoch 58/100\n",
            "{\"epoch\": 57, \"loss\": 0.07320995628833771, \"val_loss\": 1.8097918033599854}\n",
            "118/118 - 7s - loss: 0.0732 - accuracy: 0.9680 - val_loss: 1.8098 - val_accuracy: 0.7030 - 7s/epoch - 62ms/step\n",
            "Epoch 59/100\n",
            "{\"epoch\": 58, \"loss\": 0.07434964179992676, \"val_loss\": 1.8740839958190918}\n",
            "118/118 - 7s - loss: 0.0743 - accuracy: 0.9679 - val_loss: 1.8741 - val_accuracy: 0.7000 - 7s/epoch - 62ms/step\n",
            "Epoch 60/100\n",
            "{\"epoch\": 59, \"loss\": 0.07406499981880188, \"val_loss\": 1.9198304414749146}\n",
            "118/118 - 7s - loss: 0.0741 - accuracy: 0.9661 - val_loss: 1.9198 - val_accuracy: 0.7050 - 7s/epoch - 62ms/step\n",
            "Epoch 61/100\n",
            "{\"epoch\": 60, \"loss\": 0.07191596925258636, \"val_loss\": 1.844078779220581}\n",
            "118/118 - 8s - loss: 0.0719 - accuracy: 0.9678 - val_loss: 1.8441 - val_accuracy: 0.7070 - 8s/epoch - 64ms/step\n",
            "Epoch 62/100\n",
            "{\"epoch\": 61, \"loss\": 0.07155060768127441, \"val_loss\": 1.8744220733642578}\n",
            "118/118 - 7s - loss: 0.0716 - accuracy: 0.9680 - val_loss: 1.8744 - val_accuracy: 0.6940 - 7s/epoch - 62ms/step\n",
            "Epoch 63/100\n",
            "{\"epoch\": 62, \"loss\": 0.0725303590297699, \"val_loss\": 1.8872863054275513}\n",
            "118/118 - 7s - loss: 0.0725 - accuracy: 0.9687 - val_loss: 1.8873 - val_accuracy: 0.7060 - 7s/epoch - 62ms/step\n",
            "Epoch 64/100\n",
            "{\"epoch\": 63, \"loss\": 0.07246490567922592, \"val_loss\": 1.849256157875061}\n",
            "118/118 - 7s - loss: 0.0725 - accuracy: 0.9667 - val_loss: 1.8493 - val_accuracy: 0.7110 - 7s/epoch - 62ms/step\n",
            "Epoch 65/100\n",
            "{\"epoch\": 64, \"loss\": 0.07071416825056076, \"val_loss\": 1.7904330492019653}\n",
            "118/118 - 7s - loss: 0.0707 - accuracy: 0.9679 - val_loss: 1.7904 - val_accuracy: 0.6810 - 7s/epoch - 62ms/step\n",
            "Epoch 66/100\n",
            "{\"epoch\": 65, \"loss\": 0.06787734478712082, \"val_loss\": 1.8907960653305054}\n",
            "118/118 - 7s - loss: 0.0679 - accuracy: 0.9692 - val_loss: 1.8908 - val_accuracy: 0.7000 - 7s/epoch - 62ms/step\n",
            "Epoch 67/100\n",
            "{\"epoch\": 66, \"loss\": 0.06874432414770126, \"val_loss\": 1.8100656270980835}\n",
            "118/118 - 7s - loss: 0.0687 - accuracy: 0.9697 - val_loss: 1.8101 - val_accuracy: 0.6930 - 7s/epoch - 61ms/step\n",
            "Epoch 68/100\n",
            "{\"epoch\": 67, \"loss\": 0.06435362994670868, \"val_loss\": 1.9746609926223755}\n",
            "118/118 - 7s - loss: 0.0644 - accuracy: 0.9694 - val_loss: 1.9747 - val_accuracy: 0.6900 - 7s/epoch - 62ms/step\n",
            "Epoch 69/100\n",
            "{\"epoch\": 68, \"loss\": 0.06614845246076584, \"val_loss\": 1.9893354177474976}\n",
            "118/118 - 7s - loss: 0.0661 - accuracy: 0.9685 - val_loss: 1.9893 - val_accuracy: 0.7010 - 7s/epoch - 62ms/step\n",
            "Epoch 70/100\n",
            "{\"epoch\": 69, \"loss\": 0.06667160987854004, \"val_loss\": 2.0703065395355225}\n",
            "118/118 - 7s - loss: 0.0667 - accuracy: 0.9688 - val_loss: 2.0703 - val_accuracy: 0.6820 - 7s/epoch - 62ms/step\n",
            "Epoch 71/100\n",
            "{\"epoch\": 70, \"loss\": 0.06617723405361176, \"val_loss\": 2.131342887878418}\n",
            "118/118 - 7s - loss: 0.0662 - accuracy: 0.9689 - val_loss: 2.1313 - val_accuracy: 0.6810 - 7s/epoch - 61ms/step\n",
            "Epoch 72/100\n",
            "{\"epoch\": 71, \"loss\": 0.06344594061374664, \"val_loss\": 1.9193016290664673}\n",
            "118/118 - 7s - loss: 0.0634 - accuracy: 0.9698 - val_loss: 1.9193 - val_accuracy: 0.7180 - 7s/epoch - 61ms/step\n",
            "Epoch 73/100\n",
            "{\"epoch\": 72, \"loss\": 0.0644218698143959, \"val_loss\": 2.0788323879241943}\n",
            "118/118 - 7s - loss: 0.0644 - accuracy: 0.9693 - val_loss: 2.0788 - val_accuracy: 0.6870 - 7s/epoch - 62ms/step\n",
            "Epoch 74/100\n",
            "{\"epoch\": 73, \"loss\": 0.06735748052597046, \"val_loss\": 1.9951525926589966}\n",
            "118/118 - 7s - loss: 0.0674 - accuracy: 0.9672 - val_loss: 1.9952 - val_accuracy: 0.6930 - 7s/epoch - 63ms/step\n",
            "Epoch 75/100\n",
            "{\"epoch\": 74, \"loss\": 0.06457741558551788, \"val_loss\": 2.0938289165496826}\n",
            "118/118 - 7s - loss: 0.0646 - accuracy: 0.9685 - val_loss: 2.0938 - val_accuracy: 0.6880 - 7s/epoch - 62ms/step\n",
            "Epoch 76/100\n",
            "{\"epoch\": 75, \"loss\": 0.06191619485616684, \"val_loss\": 2.02945613861084}\n",
            "118/118 - 7s - loss: 0.0619 - accuracy: 0.9688 - val_loss: 2.0295 - val_accuracy: 0.6960 - 7s/epoch - 61ms/step\n",
            "Epoch 77/100\n",
            "{\"epoch\": 76, \"loss\": 0.06369198858737946, \"val_loss\": 2.138637065887451}\n",
            "118/118 - 7s - loss: 0.0637 - accuracy: 0.9689 - val_loss: 2.1386 - val_accuracy: 0.6950 - 7s/epoch - 61ms/step\n",
            "Epoch 78/100\n",
            "{\"epoch\": 77, \"loss\": 0.0632350966334343, \"val_loss\": 1.9731957912445068}\n",
            "118/118 - 8s - loss: 0.0632 - accuracy: 0.9696 - val_loss: 1.9732 - val_accuracy: 0.7000 - 8s/epoch - 64ms/step\n",
            "Epoch 79/100\n",
            "{\"epoch\": 78, \"loss\": 0.06500574946403503, \"val_loss\": 2.1243820190429688}\n",
            "118/118 - 7s - loss: 0.0650 - accuracy: 0.9676 - val_loss: 2.1244 - val_accuracy: 0.6940 - 7s/epoch - 62ms/step\n",
            "Epoch 80/100\n",
            "{\"epoch\": 79, \"loss\": 0.06290566176176071, \"val_loss\": 2.0314207077026367}\n",
            "118/118 - 7s - loss: 0.0629 - accuracy: 0.9692 - val_loss: 2.0314 - val_accuracy: 0.7010 - 7s/epoch - 61ms/step\n",
            "Epoch 81/100\n",
            "{\"epoch\": 80, \"loss\": 0.06297779828310013, \"val_loss\": 2.002284049987793}\n",
            "118/118 - 7s - loss: 0.0630 - accuracy: 0.9683 - val_loss: 2.0023 - val_accuracy: 0.7010 - 7s/epoch - 61ms/step\n",
            "Epoch 82/100\n",
            "{\"epoch\": 81, \"loss\": 0.06455458700656891, \"val_loss\": 2.113016128540039}\n",
            "118/118 - 7s - loss: 0.0646 - accuracy: 0.9681 - val_loss: 2.1130 - val_accuracy: 0.6960 - 7s/epoch - 62ms/step\n",
            "Epoch 83/100\n",
            "{\"epoch\": 82, \"loss\": 0.06054242327809334, \"val_loss\": 2.1432371139526367}\n",
            "118/118 - 7s - loss: 0.0605 - accuracy: 0.9699 - val_loss: 2.1432 - val_accuracy: 0.6980 - 7s/epoch - 61ms/step\n",
            "Epoch 84/100\n",
            "{\"epoch\": 83, \"loss\": 0.06226719543337822, \"val_loss\": 2.1321749687194824}\n",
            "118/118 - 7s - loss: 0.0623 - accuracy: 0.9682 - val_loss: 2.1322 - val_accuracy: 0.6940 - 7s/epoch - 61ms/step\n",
            "Epoch 85/100\n",
            "{\"epoch\": 84, \"loss\": 0.0603630468249321, \"val_loss\": 2.0759005546569824}\n",
            "118/118 - 7s - loss: 0.0604 - accuracy: 0.9687 - val_loss: 2.0759 - val_accuracy: 0.7030 - 7s/epoch - 61ms/step\n",
            "Epoch 86/100\n",
            "{\"epoch\": 85, \"loss\": 0.061033837497234344, \"val_loss\": 2.1163125038146973}\n",
            "118/118 - 7s - loss: 0.0610 - accuracy: 0.9689 - val_loss: 2.1163 - val_accuracy: 0.7050 - 7s/epoch - 61ms/step\n",
            "Epoch 87/100\n",
            "{\"epoch\": 86, \"loss\": 0.061297811567783356, \"val_loss\": 2.182849645614624}\n",
            "118/118 - 7s - loss: 0.0613 - accuracy: 0.9691 - val_loss: 2.1828 - val_accuracy: 0.7030 - 7s/epoch - 61ms/step\n",
            "Epoch 88/100\n",
            "{\"epoch\": 87, \"loss\": 0.05941145867109299, \"val_loss\": 2.2447798252105713}\n",
            "118/118 - 7s - loss: 0.0594 - accuracy: 0.9696 - val_loss: 2.2448 - val_accuracy: 0.6950 - 7s/epoch - 62ms/step\n",
            "Epoch 89/100\n",
            "{\"epoch\": 88, \"loss\": 0.06003016605973244, \"val_loss\": 2.039902925491333}\n",
            "118/118 - 7s - loss: 0.0600 - accuracy: 0.9711 - val_loss: 2.0399 - val_accuracy: 0.7130 - 7s/epoch - 61ms/step\n",
            "Epoch 90/100\n",
            "{\"epoch\": 89, \"loss\": 0.05891707167029381, \"val_loss\": 2.3040213584899902}\n",
            "118/118 - 7s - loss: 0.0589 - accuracy: 0.9691 - val_loss: 2.3040 - val_accuracy: 0.6980 - 7s/epoch - 61ms/step\n",
            "Epoch 91/100\n",
            "{\"epoch\": 90, \"loss\": 0.058804702013731, \"val_loss\": 2.2848949432373047}\n",
            "118/118 - 7s - loss: 0.0588 - accuracy: 0.9693 - val_loss: 2.2849 - val_accuracy: 0.7030 - 7s/epoch - 61ms/step\n",
            "Epoch 92/100\n",
            "{\"epoch\": 91, \"loss\": 0.058483708649873734, \"val_loss\": 2.231773853302002}\n",
            "118/118 - 7s - loss: 0.0585 - accuracy: 0.9701 - val_loss: 2.2318 - val_accuracy: 0.7020 - 7s/epoch - 62ms/step\n",
            "Epoch 93/100\n",
            "{\"epoch\": 92, \"loss\": 0.05910180136561394, \"val_loss\": 2.324490785598755}\n",
            "118/118 - 7s - loss: 0.0591 - accuracy: 0.9695 - val_loss: 2.3245 - val_accuracy: 0.6950 - 7s/epoch - 62ms/step\n",
            "Epoch 94/100\n",
            "{\"epoch\": 93, \"loss\": 0.058637235313653946, \"val_loss\": 2.0384817123413086}\n",
            "118/118 - 8s - loss: 0.0586 - accuracy: 0.9684 - val_loss: 2.0385 - val_accuracy: 0.7040 - 8s/epoch - 66ms/step\n",
            "Epoch 95/100\n",
            "{\"epoch\": 94, \"loss\": 0.05738870054483414, \"val_loss\": 2.226656436920166}\n",
            "118/118 - 8s - loss: 0.0574 - accuracy: 0.9697 - val_loss: 2.2267 - val_accuracy: 0.7050 - 8s/epoch - 64ms/step\n",
            "Epoch 96/100\n",
            "{\"epoch\": 95, \"loss\": 0.05879402533173561, \"val_loss\": 2.243136405944824}\n",
            "118/118 - 7s - loss: 0.0588 - accuracy: 0.9687 - val_loss: 2.2431 - val_accuracy: 0.6940 - 7s/epoch - 61ms/step\n",
            "Epoch 97/100\n",
            "{\"epoch\": 96, \"loss\": 0.05839691683650017, \"val_loss\": 2.250460147857666}\n",
            "118/118 - 7s - loss: 0.0584 - accuracy: 0.9691 - val_loss: 2.2505 - val_accuracy: 0.6940 - 7s/epoch - 62ms/step\n",
            "Epoch 98/100\n",
            "{\"epoch\": 97, \"loss\": 0.05414017662405968, \"val_loss\": 2.203347682952881}\n",
            "118/118 - 7s - loss: 0.0541 - accuracy: 0.9702 - val_loss: 2.2033 - val_accuracy: 0.7040 - 7s/epoch - 61ms/step\n",
            "Epoch 99/100\n",
            "{\"epoch\": 98, \"loss\": 0.05684032291173935, \"val_loss\": 2.3220596313476562}\n",
            "118/118 - 7s - loss: 0.0568 - accuracy: 0.9697 - val_loss: 2.3221 - val_accuracy: 0.6970 - 7s/epoch - 61ms/step\n",
            "Epoch 100/100\n",
            "{\"epoch\": 99, \"loss\": 0.056326836347579956, \"val_loss\": 2.194458484649658}\n",
            "118/118 - 7s - loss: 0.0563 - accuracy: 0.9694 - val_loss: 2.1945 - val_accuracy: 0.7030 - 7s/epoch - 61ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.is_gpu_available(\n",
        "    cuda_only=False,\n",
        "    min_cuda_compute_capability=None\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RARnAJf34td6",
        "outputId": "7f19bdd5-4871-48ab-d5f6-d9e0f718b905"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-27-b25d88cf26c7>:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hcsxxtCF0-jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q5QYmxQU0-mN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RFUevssa0-pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FWaUwE0u0-si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Amrfpv_f0-y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0wnl77gq0-2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cBrq3QUd0-50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bF_IdmFC0-80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k6yzFNK_0---"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cpv3z77s0_Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7HR9Cnqv0_FX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Embedding\n",
        "# define documents\n",
        "docs = ['Well done!',\n",
        "\t\t'Good work',\n",
        "\t\t'Great effort',\n",
        "\t\t'nice work',\n",
        "\t\t'Excellent!',\n",
        "\t\t'Weak',\n",
        "\t\t'Poor effort!',\n",
        "\t\t'not good',\n",
        "\t\t'poor work',\n",
        "\t\t'Could have done better.']\n",
        "# define class labels\n",
        "labels = array([1,1,1,1,1,0,0,0,0,0])\n",
        "# integer encode the documents\n",
        "vocab_size = 50\n",
        "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
        "print(encoded_docs)\n",
        "# pad documents to a max length of 4 words\n",
        "max_length = 4\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "print(padded_docs)\n",
        "# define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# summarize the model\n",
        "print(model.summary())\n",
        "# fit the model\n",
        "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
        "# evaluate the model\n",
        "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "metadata": {
        "id": "KpA6M9kBq62X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2a0d7bf-a853-4ec9-bbf6-892dd3e0b41c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[28, 7], [28, 14], [46, 4], [15, 14], [21], [15], [43, 4], [2, 28], [43, 14], [26, 1, 7, 38]]\n",
            "[[28  7  0  0]\n",
            " [28 14  0  0]\n",
            " [46  4  0  0]\n",
            " [15 14  0  0]\n",
            " [21  0  0  0]\n",
            " [15  0  0  0]\n",
            " [43  4  0  0]\n",
            " [ 2 28  0  0]\n",
            " [43 14  0  0]\n",
            " [26  1  7 38]]\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 4, 8)              400       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 433\n",
            "Trainable params: 433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Accuracy: 80.000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qiw0V41qO_e2",
        "outputId": "f36f5039-bc10-4db6-c9fb-c447d6eb1efe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-18 03:09:08--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-10-18 03:09:08--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-10-18 03:09:08--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 40s  \n",
            "\n",
            "2022-10-18 03:11:48 (5.15 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IcfvXoEO_h4",
        "outputId": "ae2cfea3-6c54-45a0-fd3b-c030dc595d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 3039136\n",
            "drwxr-xr-x 1 root root       4096 Oct 14 19:05 sample_data\n",
            "-rw-r--r-- 1 root root  862182613 Oct 25  2015 glove.6B.zip\n",
            "-rw-rw-r-- 1 root root 1037962819 Aug 27  2014 glove.6B.300d.txt\n",
            "-rw-rw-r-- 1 root root  171350079 Aug  4  2014 glove.6B.50d.txt\n",
            "-rw-rw-r-- 1 root root  693432828 Aug  4  2014 glove.6B.200d.txt\n",
            "-rw-rw-r-- 1 root root  347116733 Aug  4  2014 glove.6B.100d.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrRQJSiuQLdz",
        "outputId": "a0f94bdc-ce25-4737-d980-3bba01342558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Embedding\n",
        "# define documents\n",
        "docs = ['Well done!',\n",
        "\t\t'Good work',\n",
        "\t\t'Great effort',\n",
        "\t\t'nice work',\n",
        "\t\t'Excellent!',\n",
        "\t\t'Weak',\n",
        "\t\t'Poor effort!',\n",
        "\t\t'not good',\n",
        "\t\t'poor work',\n",
        "\t\t'Could have done better.']\n",
        "# define class labels\n",
        "labels = array([1,1,1,1,1,0,0,0,0,0])\n",
        "# prepare tokenizer\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(docs)\n",
        "vocab_size = len(t.word_index) + 1\n",
        "# integer encode the documents\n",
        "encoded_docs = t.texts_to_sequences(docs)\n",
        "print(encoded_docs)\n",
        "# pad documents to a max length of 4 words\n",
        "max_length = 4\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "print(padded_docs)\n",
        "# load the whole embedding into memory\n",
        "embeddings_index = dict()\n",
        "f = open('glove.6B.100d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))\n",
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = zeros((vocab_size, 100))\n",
        "for word, i in t.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector\n",
        "# define model\n",
        "model = Sequential()\n",
        "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=4, trainable=False)\n",
        "model.add(e)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# summarize the model\n",
        "print(model.summary())\n",
        "# fit the model\n",
        "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
        "# evaluate the model\n",
        "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8KintCyNX3A",
        "outputId": "f96efa11-bed0-40e8-a81e-d32c7ea5ae02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6, 2], [3, 1], [7, 4], [8, 1], [9], [10], [5, 4], [11, 3], [5, 1], [12, 13, 2, 14]]\n",
            "[[ 6  2  0  0]\n",
            " [ 3  1  0  0]\n",
            " [ 7  4  0  0]\n",
            " [ 8  1  0  0]\n",
            " [ 9  0  0  0]\n",
            " [10  0  0  0]\n",
            " [ 5  4  0  0]\n",
            " [11  3  0  0]\n",
            " [ 5  1  0  0]\n",
            " [12 13  2 14]]\n",
            "Loaded 400000 word vectors.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 4, 100)            1500      \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 401       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,901\n",
            "Trainable params: 401\n",
            "Non-trainable params: 1,500\n",
            "_________________________________________________________________\n",
            "None\n",
            "Accuracy: 100.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EHdlGmllNX6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('news20.tar.gz') "
      ],
      "metadata": {
        "id": "LFh4Bn3jNX9D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ab367606-d25f-42dd-8e0c-805cf970580d"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0a576bb7-9835-4db4-80ae-a802eb5666d7\", \"news20.tar.gz\", 17329808)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bdKKz36BNYAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "guG7Fb0YNYDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oB4UYXzpNYGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-185_dCINYL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yp8P7YpxNYPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GNjWqhCqErky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zt09Xx7yErnJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}